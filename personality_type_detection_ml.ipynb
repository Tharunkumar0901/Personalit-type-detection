{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Data Analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Data Visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import wordcloud\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Text Processing\n",
        "import re\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Machine Learning packages\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "# Model training and evaluation\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Models\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "#Metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Ignore noise warning\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "VodslOZLq7yDsyHvfjnQlG",
          "type": "CODE"
        },
        "pycharm": {
          "is_executing": true
        },
        "execution": {
          "iopub.status.busy": "2023-04-21T15:23:10.113370Z",
          "iopub.execute_input": "2023-04-21T15:23:10.114228Z",
          "iopub.status.idle": "2023-04-21T15:23:12.120245Z",
          "shell.execute_reply.started": "2023-04-21T15:23:10.114116Z",
          "shell.execute_reply": "2023-04-21T15:23:12.118953Z"
        },
        "trusted": true,
        "id": "OGogooa6x34X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MBTI_DS = pd.read_csv(\"mbti_1.csv\")\n",
        "MBTI_DS.tail()"
      ],
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "YpwzUKLjsGxuDGPUznZIaF",
          "type": "CODE"
        },
        "pycharm": {
          "is_executing": true
        },
        "execution": {
          "iopub.status.busy": "2023-04-21T15:23:12.122880Z",
          "iopub.execute_input": "2023-04-21T15:23:12.123383Z",
          "iopub.status.idle": "2023-04-21T15:23:13.976062Z",
          "shell.execute_reply.started": "2023-04-21T15:23:12.123336Z",
          "shell.execute_reply": "2023-04-21T15:23:13.974596Z"
        },
        "trusted": true,
        "id": "fdz6smCLx34Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MBTI_DS.isnull().any()"
      ],
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "CG3gDN3vwklkhCOZYJaoCt",
          "type": "CODE"
        },
        "execution": {
          "iopub.status.busy": "2023-04-21T15:23:13.978072Z",
          "iopub.execute_input": "2023-04-21T15:23:13.979794Z",
          "iopub.status.idle": "2023-04-21T15:23:14.005880Z",
          "shell.execute_reply.started": "2023-04-21T15:23:13.979742Z",
          "shell.execute_reply": "2023-04-21T15:23:14.003664Z"
        },
        "trusted": true,
        "id": "X4Hwp7hHx34Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nRow, nCol = MBTI_DS.shape\n",
        "print(f'There are {nRow} rows and {nCol} columns')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-21T15:23:14.007176Z",
          "iopub.execute_input": "2023-04-21T15:23:14.007671Z",
          "iopub.status.idle": "2023-04-21T15:23:14.017035Z",
          "shell.execute_reply.started": "2023-04-21T15:23:14.007628Z",
          "shell.execute_reply": "2023-04-21T15:23:14.016077Z"
        },
        "trusted": true,
        "id": "fD0k5Ewux34a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MBTI_DS.dtypes\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-21T15:23:14.020388Z",
          "iopub.execute_input": "2023-04-21T15:23:14.020860Z",
          "iopub.status.idle": "2023-04-21T15:23:14.031878Z",
          "shell.execute_reply.started": "2023-04-21T15:23:14.020814Z",
          "shell.execute_reply": "2023-04-21T15:23:14.030704Z"
        },
        "trusted": true,
        "id": "ttyUSWNXx34a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MBTI_DS.info()"
      ],
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "SbReCrOLA8xITnfPd2HTRO",
          "type": "CODE"
        },
        "execution": {
          "iopub.status.busy": "2023-04-21T15:23:14.033829Z",
          "iopub.execute_input": "2023-04-21T15:23:14.034277Z",
          "iopub.status.idle": "2023-04-21T15:23:14.063417Z",
          "shell.execute_reply.started": "2023-04-21T15:23:14.034223Z",
          "shell.execute_reply": "2023-04-21T15:23:14.062025Z"
        },
        "trusted": true,
        "id": "A-y5bbnzx34a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **SUMMARY**\n",
        "\n",
        "#### - JUST 2 columns in MBTI DATASET\n",
        "#### - Number rows IS 8675\n",
        "#### - No null valuesin MBTI DATASET\n",
        "#### - -All values are textual, So we should convert to numeric form to train the Machine Learning model"
      ],
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "Ot6vuolPG3dQ8xktDxFmEB",
          "type": "MD"
        },
        "id": "s6NII7Lgx34a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MBTI_DS.describe(include=['object'])"
      ],
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "xsiISbVwpg9GwVWtl7098e",
          "type": "CODE"
        },
        "execution": {
          "iopub.status.busy": "2023-04-21T15:23:14.065256Z",
          "iopub.execute_input": "2023-04-21T15:23:14.066218Z",
          "iopub.status.idle": "2023-04-21T15:23:14.154942Z",
          "shell.execute_reply.started": "2023-04-21T15:23:14.066178Z",
          "shell.execute_reply": "2023-04-21T15:23:14.153038Z"
        },
        "trusted": true,
        "id": "LNgO6x03x34c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We see**\n",
        "There are 16 unique personality type indicators in the dataset\n",
        "**INFP** most frequently occuring personality type\n",
        "\n",
        "Number of occurences is 1832"
      ],
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "4tbcZzRpFpxOHgBh6n64zJ",
          "type": "MD"
        },
        "id": "rAuQKaEux34c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "types = np.unique(np.array(MBTI_DS['type']))\n",
        "print(\"The Unique values 'type' of personality column\",types)"
      ],
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "T0vRYCwF7HvqAv6FcJThdV",
          "type": "CODE"
        },
        "execution": {
          "iopub.status.busy": "2023-04-21T15:23:14.156947Z",
          "iopub.execute_input": "2023-04-21T15:23:14.157411Z",
          "iopub.status.idle": "2023-04-21T15:23:14.172297Z",
          "shell.execute_reply.started": "2023-04-21T15:23:14.157375Z",
          "shell.execute_reply": "2023-04-21T15:23:14.170344Z"
        },
        "trusted": true,
        "id": "X4Je-ZiKx34c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total = MBTI_DS.groupby(['type']).count()*50\n",
        "print(\"The Total Posts for every Personality Type\")\n",
        "total"
      ],
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "J3ND8Q9YyRGSrObK8sYNlX",
          "type": "CODE"
        },
        "execution": {
          "iopub.status.busy": "2023-04-21T15:23:14.174246Z",
          "iopub.execute_input": "2023-04-21T15:23:14.175586Z",
          "iopub.status.idle": "2023-04-21T15:23:14.199776Z",
          "shell.execute_reply.started": "2023-04-21T15:23:14.175506Z",
          "shell.execute_reply": "2023-04-21T15:23:14.198260Z"
        },
        "trusted": true,
        "id": "sg6nxLTOx34d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data visualization**"
      ],
      "metadata": {
        "id": "XKNY07kAx34d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,3))\n",
        "plt.bar(np.array(total.index), height = total['posts'],)\n",
        "plt.xlabel('Personality types', size = 12)\n",
        "plt.ylabel('Number post available', size = 12)\n",
        "plt.title('Total post each personality type')"
      ],
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "1Xgcv78IczINKozsXsCXWG",
          "type": "CODE"
        },
        "execution": {
          "iopub.status.busy": "2023-04-21T15:23:14.201407Z",
          "iopub.execute_input": "2023-04-21T15:23:14.202440Z",
          "iopub.status.idle": "2023-04-21T15:23:14.560210Z",
          "shell.execute_reply.started": "2023-04-21T15:23:14.202389Z",
          "shell.execute_reply": "2023-04-21T15:23:14.558734Z"
        },
        "trusted": true,
        "id": "239-1-fXx34d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The MBTI DATASET is unbalanced throughout the different classes. Some personality types has more data than others, The **INFP (Introvert Intuition Feeling Perceiving)** the highest"
      ],
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "5hy57AjsW56ORgxiyhIcQz",
          "type": "MD"
        },
        "id": "3HvMKecEx34e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the original dataset only came with 2 features, the Type and 50 posts for each person, we decided to create additional features for exploring & analysing our dataset.\n",
        "\n",
        "After we added our features, we did some data exploration to see how the raw data looks and to see how important our features were for distinguishing types across the MBTI personalities. Below are plots further showing the type imbalances in our data.\n"
      ],
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "4P6eaE5dwMAwwDcZ7D4jgP",
          "type": "MD"
        },
        "id": "idIxTw8Ox34e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MBTI_DS_C = MBTI_DS.copy()\n",
        "#Count Number words for each post of a user\n",
        "def var_row(row):\n",
        "    l = []\n",
        "    for i in row.split('|||'):\n",
        "        l.append(len(i.split()))\n",
        "    return np.var(l)\n",
        "\n",
        "#Count Number words per post for total 50 posts in whole row\n",
        "MBTI_DS_C['word_each_comment'] = MBTI_DS_C['posts'].apply(lambda x: len(x.split())/50)\n",
        "MBTI_DS_C['variance_word_count'] = MBTI_DS_C['posts'].apply(lambda x: var_row(x))\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "sns.swarmplot(x=\"type\",y=\"word_each_comment\", data=MBTI_DS_C)"
      ],
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "HbrM0ouffQuvUpUMCHYZN8",
          "type": "CODE"
        },
        "execution": {
          "iopub.status.busy": "2023-04-21T15:23:14.562253Z",
          "iopub.execute_input": "2023-04-21T15:23:14.562826Z",
          "iopub.status.idle": "2023-04-21T15:23:22.108181Z",
          "shell.execute_reply.started": "2023-04-21T15:23:14.562779Z",
          "shell.execute_reply": "2023-04-21T15:23:22.107006Z"
        },
        "trusted": true,
        "id": "orvBT6Ytx34e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INFP** has the most cluttered showing there are most number of comments of this type of personality"
      ],
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "wnLIOrlqY870IWnfAFy3om",
          "type": "MD"
        },
        "id": "6NFzGIZSx34e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DISTANCE PLOT** This seaborn visualization method shows the histogram distribution data for single column."
      ],
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "99GDsgxMNHRSUf8OMO9mKa",
          "type": "MD"
        },
        "id": "INreWPzlx34f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MBTI_DS[\"length_posts\"] = MBTI_DS[\"posts\"].apply(len)\n",
        "sns.distplot(MBTI_DS[\"length_posts\"]).set_title(\"Distribution of Lengths of all 50 Posts\")"
      ],
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "VjsVNjMV9YQFNeIHWfYDv5",
          "type": "CODE"
        },
        "execution": {
          "iopub.status.busy": "2023-04-21T15:23:22.109746Z",
          "iopub.execute_input": "2023-04-21T15:23:22.111044Z",
          "iopub.status.idle": "2023-04-21T15:23:22.479642Z",
          "shell.execute_reply.started": "2023-04-21T15:23:22.110976Z",
          "shell.execute_reply": "2023-04-21T15:23:22.478526Z"
        },
        "trusted": true,
        "id": "zzNp4x1rx34f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that most no of lengthly posts have between **7000-9000 words**."
      ],
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "MFJv1cpdUgUiwuZ0OjN8eq",
          "type": "MD"
        },
        "id": "8mpUCufvx34g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding the most common words in all posts.\n",
        "words = list(MBTI_DS[\"posts\"].apply(lambda x: x.split()))\n",
        "words = [x for y in words for x in y]\n",
        "Counter(words).most_common(50)"
      ],
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "aI8Szja9Rxul5B23MhMGZ4",
          "type": "CODE"
        },
        "execution": {
          "iopub.status.busy": "2023-04-21T15:23:22.480985Z",
          "iopub.execute_input": "2023-04-21T15:23:22.481313Z",
          "iopub.status.idle": "2023-04-21T15:23:26.854157Z",
          "shell.execute_reply.started": "2023-04-21T15:23:22.481283Z",
          "shell.execute_reply": "2023-04-21T15:23:26.853100Z"
        },
        "trusted": true,
        "id": "EgcMKwdIx34g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The posts contain general words like : I, to, the, a, and, of, is, you etc. \n",
        "\n",
        "we assume that these words don't really provide any useful information to train the Machine Learning model as most of them are stop-words or other useless words.\n"
      ],
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "Mpkwa5fqjXGT9nTcUGOvZo",
          "type": "MD"
        },
        "id": "7j_AXMysx34g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WORDCLOUD**"
      ],
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "51D6vUP9e4HOqgB1kjtA6F",
          "type": "MD"
        },
        "id": "Hj6py-XVx34g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "wc = wordcloud.WordCloud(width=1200, height=500, collocations=False, background_color=\"white\", colormap=\"tab20b\").generate(\" \".join(words))\n",
        "\n",
        "# collocations to False  is set to ensure that the word cloud doesn't appear as if it contains any duplicate words\n",
        "plt.figure(figsize=(25,10))\n",
        "# generate word cloud, interpolation \n",
        "plt.imshow(wc, interpolation='bilinear')\n",
        "_ = plt.axis(\"off\")"
      ],
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "Ge4Q6b33AMkuZviWVShGxh",
          "type": "CODE"
        },
        "execution": {
          "iopub.status.busy": "2023-04-21T15:23:26.858311Z",
          "iopub.execute_input": "2023-04-21T15:23:26.858661Z",
          "iopub.status.idle": "2023-04-21T15:23:44.686056Z",
          "shell.execute_reply.started": "2023-04-21T15:23:26.858630Z",
          "shell.execute_reply": "2023-04-21T15:23:44.684758Z"
        },
        "trusted": true,
        "id": "5eYY2qNHx34g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(len(MBTI_DS['type'].unique()), figsize=(15,len(MBTI_DS['type'].unique())))\n",
        "k = 0\n",
        "for i in MBTI_DS['type'].unique():\n",
        "    df_4 = MBTI_DS[MBTI_DS['type'] == i]\n",
        "    wordcloud = WordCloud(max_words=1628,relative_scaling=1,normalize_plurals=False).generate(df_4['posts'].to_string())\n",
        "    plt.subplot(4,4,k+1)\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.title(i)\n",
        "    ax[k].axis(\"off\")\n",
        "    k+=1"
      ],
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "IuqF7voTB17L1ZHP1BUHl4",
          "type": "CODE"
        },
        "execution": {
          "iopub.status.busy": "2023-04-21T15:23:44.687817Z",
          "iopub.execute_input": "2023-04-21T15:23:44.688190Z",
          "iopub.status.idle": "2023-04-21T15:23:52.043102Z",
          "shell.execute_reply.started": "2023-04-21T15:23:44.688156Z",
          "shell.execute_reply": "2023-04-21T15:23:52.042058Z"
        },
        "trusted": true,
        "id": "IFAZccqlx34h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see there are a number of irrelevant words present in the dataset **(e.g. ha, ar, Ti etx.)** which will need to be removed Interestingly, among the most common words in the word clouds of individual personality types, is the **names of MBTI personlity types themselves**.\n",
        "It would hence be necessary to clean our posts by removing these MBTI words from each of them as part of our pre-processing stage, before training the model for better evaluation results.\n"
      ],
      "metadata": {
        "id": "HYgPzPJex34h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#add columns for personality type indicators\n",
        "\n",
        "def get_types(row):\n",
        "    t=row['type']\n",
        "\n",
        "    I = 0; N = 0\n",
        "    T = 0; J = 0\n",
        "    \n",
        "    if t[0] == 'I': I = 1\n",
        "    elif t[0] == 'E': I = 0\n",
        "    else: print('I-E not found') \n",
        "        \n",
        "    if t[1] == 'N': N = 1\n",
        "    elif t[1] == 'S': N = 0\n",
        "    else: print('N-S not found')\n",
        "        \n",
        "    if t[2] == 'T': T = 1\n",
        "    elif t[2] == 'F': T = 0\n",
        "    else: print('T-F not found')\n",
        "        \n",
        "    if t[3] == 'J': J = 1\n",
        "    elif t[3] == 'P': J = 0\n",
        "    else: print('J-P not found')\n",
        "    return pd.Series( {'IE':I, 'NS':N , 'TF': T, 'JP': J }) \n",
        "\n",
        "MBTI_DS_N = MBTI_DS.join(MBTI_DS.apply (lambda row: get_types (row),axis=1))\n",
        "MBTI_DS_N.head(5)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-21T15:23:52.044667Z",
          "iopub.execute_input": "2023-04-21T15:23:52.045195Z",
          "iopub.status.idle": "2023-04-21T15:23:55.386590Z",
          "shell.execute_reply.started": "2023-04-21T15:23:52.045134Z",
          "shell.execute_reply": "2023-04-21T15:23:55.385373Z"
        },
        "trusted": true,
        "id": "Xn-X6qWsx34h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code assigns a value of 1 to individuals who possess the traits of Introversion (I), Intuition (N), Thinking (T), and Judging (J) on the four axes of the Myers-Briggs Type Indicator (MBTI) - Introversion-Extraversion (IE), Intuition-Sensing (NS), Feeling-Thinking (FT), and Judging-Perceiving (JP). All other individuals are assigned a value of 0.\n",
        "\n",
        "This allows us to calculate the number of posts that correspond to introverted individuals versus extroverted individuals out of all the entries in the labeled Kaggle dataset. This analysis is conducted to examine the dataset for each individual personality index of the MBTI.\n"
      ],
      "metadata": {
        "id": "spBySXDGx34h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Counting Number posts in one class | Total Number posts in other class\n",
        "\n",
        "print (\"Introversion (I) |  Extroversion (E): \\t\", MBTI_DS_N['IE'].value_counts()[0], \" | \", MBTI_DS_N['IE'].value_counts()[1])\n",
        "print (\"Intuition    (N) |  Sensing      (S): \\t\", MBTI_DS_N['NS'].value_counts()[0], \" | \", MBTI_DS_N['NS'].value_counts()[1])\n",
        "print (\"Thinking     (T) |  Feeling      (F): \\t\", MBTI_DS_N['TF'].value_counts()[0], \" | \", MBTI_DS_N['TF'].value_counts()[1])\n",
        "print (\"Judging      (J) |  Perceiving   (P): \\t\", MBTI_DS_N['JP'].value_counts()[0], \" | \", MBTI_DS_N['JP'].value_counts()[1])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-21T15:23:55.387932Z",
          "iopub.execute_input": "2023-04-21T15:23:55.389072Z",
          "iopub.status.idle": "2023-04-21T15:23:55.402459Z",
          "shell.execute_reply.started": "2023-04-21T15:23:55.389022Z",
          "shell.execute_reply": "2023-04-21T15:23:55.401149Z"
        },
        "trusted": true,
        "id": "sUezx24Rx34h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that there is an uneven distribution of the entries in our dataset across the four axes of the MBTI, with E being the majority in the IE axis, S being the majority in the NS axis, and relatively less difference between T and F in the TF axis, and J and P in the JP axis.\n"
      ],
      "metadata": {
        "id": "sY_UWQkxx34i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the distribution of each personality type indicator\n",
        "N = 4\n",
        "bottom = (MBTI_DS_N['IE'].value_counts()[0], MBTI_DS_N['NS'].value_counts()[0], MBTI_DS_N['TF'].value_counts()[0], MBTI_DS_N['JP'].value_counts()[0])\n",
        "top = (MBTI_DS_N['IE'].value_counts()[1], MBTI_DS_N['NS'].value_counts()[1], MBTI_DS_N['TF'].value_counts()[1], MBTI_DS_N['JP'].value_counts()[1])\n",
        "\n",
        "ind = np.arange(N)    # the x locations for the groups\n",
        "# the width of the bars\n",
        "width = 0.7\n",
        "\n",
        "p1 = plt.bar(ind, bottom, width, label=\"I, N, T, F\")\n",
        "p2 = plt.bar(ind, top, width, bottom=bottom, label=\"E, S, F, P\") \n",
        "\n",
        "plt.title('Distribution accoss types indicators')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(ind, ('I / E',  'N / S', 'T / F', 'J / P',))\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-21T15:23:55.403775Z",
          "iopub.execute_input": "2023-04-21T15:23:55.404205Z",
          "iopub.status.idle": "2023-04-21T15:23:55.628728Z",
          "shell.execute_reply.started": "2023-04-21T15:23:55.404176Z",
          "shell.execute_reply": "2023-04-21T15:23:55.627447Z"
        },
        "trusted": true,
        "id": "7MBsr1kYx34i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cmap = plt.cm.RdBu\n",
        "corr = MBTI_DS_N[['IE','NS','TF','JP']].corr()\n",
        "plt.figure(figsize=(12,10))\n",
        "plt.title('Features Correlation Heatmap', size=15)\n",
        "sns.heatmap(corr, cmap=cmap,  annot=True, linewidths=1)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-21T15:23:55.629941Z",
          "iopub.execute_input": "2023-04-21T15:23:55.630279Z",
          "iopub.status.idle": "2023-04-21T15:23:55.977424Z",
          "shell.execute_reply.started": "2023-04-21T15:23:55.630250Z",
          "shell.execute_reply": "2023-04-21T15:23:55.976232Z"
        },
        "trusted": true,
        "id": "HkZhejsyx34i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this heatmap also, it is unclear if it shows anything valuable for interpretation\n",
        "\n"
      ],
      "metadata": {
        "id": "wBMKTRJMx34i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SUMMARY**\n",
        "We notice that there are a number of irrelevant words present in the dataset, such as \"ha,\" \"ar,\" and \"Ti,\" which need to be removed. Additionally, we observe that among the most frequent words in the word clouds of individual personality types, are the names of the MBTI personality types themselves. Therefore, it is important to clean the posts by removing these MBTI words from each of them as part of the pre-processing stage before training the model to achieve better evaluation results."
      ],
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "UckJyJWdq1x9B3Y9Z97sTO",
          "type": "MD"
        },
        "id": "9eZY1FYtx34i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre-Processing Stage**"
      ],
      "metadata": {
        "id": "O5-E_1ifx34i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We preprocess the posts by using Lemmatization technique. Lemmatization groups together different inflected forms of a word so they can be analyzed as a single item. Unlike stemming, lemmatization takes into account the context of the word, making it a more suitable choice for our model. This technique links words with similar meanings to one word, resulting in a more accurate analysis."
      ],
      "metadata": {
        "id": "5GMSvJJ0x34i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "lemmatiser = WordNetLemmatizer()\n",
        "\n",
        "# Remove the stop words for speed \n",
        "useless_words = stopwords.words(\"english\")\n",
        "\n",
        "# Remove these from the posts\n",
        "unique_type_list = ['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP','ISFP', 'ISTP', 'ISFJ', 'ISTJ', 'ESTP', 'ESFP', 'ESTJ', 'ESFJ']\n",
        "unique_type_list = [x.lower() for x in unique_type_list]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-21T15:23:55.978862Z",
          "iopub.execute_input": "2023-04-21T15:23:55.979219Z",
          "iopub.status.idle": "2023-04-21T15:23:55.989907Z",
          "shell.execute_reply.started": "2023-04-21T15:23:55.979183Z",
          "shell.execute_reply": "2023-04-21T15:23:55.988705Z"
        },
        "trusted": true,
        "id": "jNf0Ca_gx34i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Binarizing the each personality type feature\n",
        "\n"
      ],
      "metadata": {
        "id": "i_BVrNpcx34i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the MBTI personality into 4 letters and binarizing it\n",
        "\n",
        "b_Pers = {'I':0, 'E':1, 'N':0, 'S':1, 'F':0, 'T':1, 'J':0, 'P':1}\n",
        "b_Pers_list = [{0:'I', 1:'E'}, {0:'N', 1:'S'}, {0:'F', 1:'T'}, {0:'J', 1:'P'}]\n",
        "\n",
        "def translate_personality(personality):\n",
        "    # Transform MBTI to binary vector\n",
        "    return [b_Pers[l] for l in personality]\n",
        "\n",
        "#Show result output for personality prediction\n",
        "def translate_back(personality):\n",
        "    # transform binary vector to MBTI personality\n",
        "    s = \"\"\n",
        "    for i, l in enumerate(personality):\n",
        "        s += b_Pers_list[i][l]\n",
        "    return s\n",
        "\n",
        "list_personality_bin = np.array([translate_personality(p) for p in MBTI_DS_N.type])\n",
        "print(\"Binarize MBTI list: \\n%s\" % list_personality_bin)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-21T15:23:55.991329Z",
          "iopub.execute_input": "2023-04-21T15:23:55.991676Z",
          "iopub.status.idle": "2023-04-21T15:23:56.018402Z",
          "shell.execute_reply.started": "2023-04-21T15:23:55.991646Z",
          "shell.execute_reply": "2023-04-21T15:23:56.017377Z"
        },
        "trusted": true,
        "id": "aTdxAuxHx34j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cleaning Data in posts**"
      ],
      "metadata": {
        "id": "EMz-F19jx34j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "STOPWORDS = set(stopwords.words('english'))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-21T15:23:56.020157Z",
          "iopub.execute_input": "2023-04-21T15:23:56.020475Z",
          "iopub.status.idle": "2023-04-21T15:24:36.097072Z",
          "shell.execute_reply.started": "2023-04-21T15:23:56.020447Z",
          "shell.execute_reply": "2023-04-21T15:24:36.095894Z"
        },
        "trusted": true,
        "id": "w_HO6nXqx34j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_process_text(MBTI_DS_N, remove_stop_words=True, remove_mbti_profiles=True):\n",
        "  list_personality = []\n",
        "  list_posts = []\n",
        "  len_MBTI_DS_N = len(MBTI_DS_N)\n",
        "  i=0\n",
        "  \n",
        "  for row in MBTI_DS_N.iterrows():\n",
        "      #Remove and clean comments\n",
        "      posts = row[1].posts\n",
        "\n",
        "      #Remove url links \n",
        "      temp = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', posts)\n",
        "\n",
        "      #Remove Non-words - keep only words\n",
        "      temp = re.sub(\"[^a-zA-Z]\", \" \", temp)\n",
        "\n",
        "      # Remove spaces > 1\n",
        "      temp = re.sub(' +', ' ', temp).lower()\n",
        "\n",
        "      #Remove multiple letter repeating words\n",
        "      temp = re.sub(r'([a-z])\\1{2,}[\\s|\\w]*', '', temp)\n",
        "\n",
        "      #Remove stop words\n",
        "      if remove_stop_words:\n",
        "          temp = \" \".join([lemmatiser.lemmatize(w) for w in temp.split(' ') if w not in useless_words])\n",
        "      else:\n",
        "          temp = \" \".join([lemmatiser.lemmatize(w) for w in temp.split(' ')])\n",
        "          \n",
        "      #Remove MBTI personality words from posts\n",
        "      if remove_mbti_profiles:\n",
        "          for t in unique_type_list:\n",
        "              temp = temp.replace(t,\"\")\n",
        "\n",
        "      # transform mbti to binary vector\n",
        "      type_labelized = translate_personality(row[1].type) #or use lab_encoder.transform([row[1].type])[0]\n",
        "      list_personality.append(type_labelized)\n",
        "      # the cleaned data temp is passed here\n",
        "      list_posts.append(temp)\n",
        "\n",
        "  # returns the result\n",
        "  list_posts = np.array(list_posts)\n",
        "  list_personality = np.array(list_personality)\n",
        "  return list_posts, list_personality\n",
        "\n",
        "list_posts, list_personality  = pre_process_text(MBTI_DS_N, remove_stop_words=True, remove_mbti_profiles=True)\n",
        "\n",
        "print(\"Example :\")\n",
        "print(\"\\nPost before preprocessing:\\n\\n\", MBTI_DS_N.posts[0])\n",
        "print(\"\\nPost after preprocessing:\\n\\n\", list_posts[0])\n",
        "print(\"\\nMBTI before preprocessing:\\n\\n\", MBTI_DS_N.type[0])\n",
        "print(\"\\nMBTI after preprocessing:\\n\\n\", list_personality[0])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-21T15:24:36.098638Z",
          "iopub.execute_input": "2023-04-21T15:24:36.098999Z",
          "iopub.status.idle": "2023-04-21T15:25:27.872064Z",
          "shell.execute_reply.started": "2023-04-21T15:24:36.098969Z",
          "shell.execute_reply": "2023-04-21T15:25:27.870761Z"
        },
        "trusted": true,
        "id": "mg2_DvnZx34l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nRow, nCol = list_personality.shape\n",
        "print(f'Number of posts = {nRow}  and No. of Personalities = {nCol} ')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-21T15:25:27.873973Z",
          "iopub.execute_input": "2023-04-21T15:25:27.874751Z",
          "iopub.status.idle": "2023-04-21T15:25:27.881331Z",
          "shell.execute_reply.started": "2023-04-21T15:25:27.874702Z",
          "shell.execute_reply": "2023-04-21T15:25:27.879989Z"
        },
        "trusted": true,
        "id": "IScXG7R7x34l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Engineering - TF-IDF**\n",
        "\n",
        "In our model, we use Tf-idf feature engineering to determine the relevance and importance of a word in relation to a document within a collection of documents. This technique is particularly useful for training individual classifiers and scoring words in machine learning algorithms for natural language processing. We vectorize the dataset using both count vectorizer and tf-idf vectorizer, while only keeping words that appear between 10-70% of the posts."
      ],
      "metadata": {
        "id": "oKGGvlqgx34n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing the database posts to a matrix of token counts for the model\n",
        "cntizer = CountVectorizer(analyzer=\"word\", \n",
        "                             max_features=1000,  \n",
        "                             max_df=0.7,\n",
        "                             min_df=0.1) \n",
        "# the feature should be made of word n-gram \n",
        "\n",
        "# Learn the vocabulary dictionary and return term-document matrix\n",
        "print(\"Using CountVectorizer :\")\n",
        "X_cnt = cntizer.fit_transform(list_posts)\n",
        "\n",
        "#The enumerate object yields pairs containing a count and a value (useful for obtaining an indexed list)\n",
        "#feature_names = list(enumerate(cntizer.get_feature_names()))\n",
        "print(\"10 feature names can be seen below\")\n",
        "#print(feature_names[0:10])\n",
        "\n",
        "# For the Standardization or Feature Scaling Stage :-\n",
        "# Transform the count matrix to a normalized tf or tf-idf representation\n",
        "tfizer = TfidfTransformer()\n",
        "\n",
        "# Learn the idf vector (fit) and transform a count matrix to a tf-idf representation\n",
        "print(\"\\nUsing Tf-idf :\")\n",
        "\n",
        "print(\"Now the dataset size is as below\")\n",
        "X_tfidf =  tfizer.fit_transform(X_cnt).toarray()\n",
        "print(X_tfidf.shape)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-21T15:25:27.882726Z",
          "iopub.execute_input": "2023-04-21T15:25:27.883062Z",
          "iopub.status.idle": "2023-04-21T15:25:31.427418Z",
          "shell.execute_reply.started": "2023-04-21T15:25:27.883034Z",
          "shell.execute_reply": "2023-04-21T15:25:31.426217Z"
        },
        "trusted": true,
        "id": "pNK2BXdyx34n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Therefore we now have 595 features for each user post.**\n"
      ],
      "metadata": {
        "id": "qXJEWOqBx34o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting into X and Y variable\n",
        "\n",
        "linkcode\n",
        "Hence we split the features as :\n",
        "\n",
        "X: User Posts in TF-IDF representation\n",
        "\n",
        "Y: Personality type in Binarized MBTI form"
      ],
      "metadata": {
        "id": "wE0ebm27x34o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "personality_type = [ \"IE: Introversion (I) | Extroversion (E)\", \"NS: Intuition    (N) | Sensing      (S)\", \n",
        "                   \"FT: Feeling      (F) | Thinking     (T)\", \"JP: Judging      (J) | Perceiving   (P)\"  ]\n",
        "\n",
        "for l in range(len(personality_type)):\n",
        "    print(personality_type[l])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-21T15:25:31.429023Z",
          "iopub.execute_input": "2023-04-21T15:25:31.429381Z",
          "iopub.status.idle": "2023-04-21T15:25:31.435402Z",
          "shell.execute_reply.started": "2023-04-21T15:25:31.429349Z",
          "shell.execute_reply": "2023-04-21T15:25:31.434008Z"
        },
        "trusted": true,
        "id": "inEL_2_6x34p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how the posts look in TF-IDF representation: (we have taken 1st post for demonstration)"
      ],
      "metadata": {
        "id": "vFJaEMJFx34q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X: First post in tf-idf representation\\n%s\" % X_tfidf[0])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-21T15:25:31.437125Z",
          "iopub.execute_input": "2023-04-21T15:25:31.437725Z",
          "iopub.status.idle": "2023-04-21T15:25:31.451890Z",
          "shell.execute_reply.started": "2023-04-21T15:25:31.437679Z",
          "shell.execute_reply": "2023-04-21T15:25:31.450723Z"
        },
        "trusted": true,
        "id": "dNs8c1Wxx34q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how the posts look in Binarized MBTI personality indicator representation: (we have taken 1st post for demonstration)\n"
      ],
      "metadata": {
        "id": "TYa-ujONx34r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"For MBTI personality type : %s\" % translate_back(list_personality[0,:]))\n",
        "print(\"Y : Binarized MBTI 1st row: %s\" % list_personality[0,:])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-21T15:25:31.453392Z",
          "iopub.execute_input": "2023-04-21T15:25:31.453725Z",
          "iopub.status.idle": "2023-04-21T15:25:31.462418Z",
          "shell.execute_reply.started": "2023-04-21T15:25:31.453698Z",
          "shell.execute_reply": "2023-04-21T15:25:31.461339Z"
        },
        "trusted": true,
        "id": "uhzW4yaux34r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Therefore we have successfully converted the textual data into numerical form**\n",
        "\n"
      ],
      "metadata": {
        "id": "vZRVhrqDx34s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training & Evaluating Models**"
      ],
      "metadata": {
        "id": "vIt375uvx34s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_tfidf\n",
        "Y = list_personality[:,l]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-21T15:25:31.463820Z",
          "iopub.execute_input": "2023-04-21T15:25:31.464286Z",
          "iopub.status.idle": "2023-04-21T15:25:31.489513Z",
          "shell.execute_reply.started": "2023-04-21T15:25:31.464245Z",
          "shell.execute_reply": "2023-04-21T15:25:31.488328Z"
        },
        "trusted": true,
        "id": "Dw2MNSnjx34s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  #KNN Classifier\n",
        "from sklearn.metrics import accuracy_score,classification_report\n",
        "\n",
        "# Tuning of K- value for Train & Test data\n",
        "dummyarray = np.empty((5,3))\n",
        "k_valchart = pd.DataFrame(dummyarray)\n",
        "k_valchart.columns = [\"K_value\",\"Train_acc\",\"Test_acc\"]\n",
        "k_vals = [1,2]\n",
        "for i in range(len(k_vals)):\n",
        "    knn_fit = KNeighborsClassifier(n_neighbors=k_vals[i],p=2,metric='minkowski')\n",
        "    knn_fit.fit(X_train,y_train)\n",
        "    print (\"\\nK-value\",k_vals[i])\n",
        "    tr_accscore = round(accuracy_score(y_train,knn_fit.predict(X_train)),3)\n",
        "    print (\"\\nK-Nearest Neighbors - Train ConfusionMatrix\\n\\n\",pd.crosstab( y_train, knn_fit.predict(X_train),rownames =[\"Actuall\"],colnames = [\"Predicted\"]) )\n",
        "    print (\"\\nK-Nearest Neighbors - Train accuracy:\",tr_accscore)\n",
        "    print (\"\\nK-Nearest Neighbors - Train Classification Report\\n\",classification_report(y_train,knn_fit.predict(X_train)))\n",
        "    ts_accscore = round(accuracy_score(y_test,knn_fit.predict(X_test)),3)\n",
        "    print (\"\\n\\nK-Nearest Neighbors - Test Confusion Matrix\\n\\n\",pd.crosstab( y_test,knn_fit.predict(X_test),rownames =[\"Actuall\"],colnames = [\"Predicted\"]))\n",
        "    print (\"\\nK-Nearest Neighbors - Test accuracy:\",ts_accscore)\n",
        "    print (\"\\nK-Nearest Neighbors - Test Classification Report\\n\",classification_report(y_test,knn_fit.predict(X_test)))\n",
        "    k_valchart.loc[i, 'K_value'] = k_vals[i]\n",
        "    k_valchart.loc[i, 'Train_acc'] = tr_accscore\n",
        "    k_valchart.loc[i, 'Test_acc'] = ts_accscore\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plot the train and test accuracy scores for different K-values\n",
        "plt.plot(k_valchart['K_value'], k_valchart['Train_acc'], label='Train accuracy')\n",
        "plt.plot(k_valchart['K_value'], k_valchart['Test_acc'], label='Test accuracy')\n",
        "plt.xlabel('K-value')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xticks(k_valchart['K_value'])\n",
        "plt.xticks([1,2])\n",
        "for a,b in zip(k_valchart[\"K_value\"],k_valchart[\"Train_acc\"]):\n",
        "    plt.text(a, b, str(b),fontsize=10)\n",
        "for a,b in zip(k_valchart[\"K_value\"],k_valchart[\"Test_acc\"]):\n",
        "    plt.text(a, b, str(b),fontsize=10)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-21T15:25:34.497495Z",
          "iopub.execute_input": "2023-04-21T15:25:34.498038Z",
          "iopub.status.idle": "2023-04-21T15:25:44.389189Z",
          "shell.execute_reply.started": "2023-04-21T15:25:34.498001Z",
          "shell.execute_reply": "2023-04-21T15:25:44.387940Z"
        },
        "trusted": true,
        "id": "Q1uI17ulx34v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBoost model for MBTI dataset \n",
        "# Individually training each mbti personlity type\n",
        "for l in range(len(personality_type)):\n",
        "    \n",
        "    Y = list_personality[:,l]\n",
        "\n",
        "    # split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "\n",
        "    # fit model on training data\n",
        "    model = XGBClassifier()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # make predictions for test data\n",
        "    y_pred = model.predict(X_test)\n",
        "    predictions = [round(value) for value in y_pred]\n",
        "    # evaluate predictions\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    \n",
        "    print(\"%s Accuracy: %.2f%%\" % (personality_type[l], accuracy * 100.0))\n",
        "    print(\"%s Classification report for Train Data\" % (personality_type[l]))\n",
        "    print(classification_report(y_train,model.predict(X_train)))\n",
        "    print(\"%s Classification report for Test Data\" % (personality_type[l]))\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-21T15:25:44.390768Z",
          "iopub.execute_input": "2023-04-21T15:25:44.391115Z",
          "iopub.status.idle": "2023-04-21T15:26:36.144083Z",
          "shell.execute_reply.started": "2023-04-21T15:25:44.391084Z",
          "shell.execute_reply": "2023-04-21T15:26:36.142997Z"
        },
        "trusted": true,
        "id": "Cv09T1iox34w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_posts = input(\"enter about yourself\")\n",
        "mydata = pd.DataFrame(data={'type': [\"INTP\"], 'posts': [my_posts]})\n",
        "my_posts, dummy  = pre_process_text(mydata, remove_stop_words=True, remove_mbti_profiles=True)\n",
        "my_X_cnt = cntizer.transform(my_posts)\n",
        "my_X_tfidf =  tfizer.transform(my_X_cnt).toarray()"
      ],
      "metadata": {
        "id": "XRJqtvUszYQG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "125e86f3-6797-4ce7-9548-a88117eb45a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enter about yourselfIt's raining (From\" Enna solla pogirai\") By @mervinsolomon Meets Play date @littlebodybigheart (YouTube link in bio!!)  Hey there guys!! I get that ..puriyudhu😂 colloborations posts frequently 😂😂😂  So anyway that's why wanted to post a small preview reel about the track Reels maybe 😂😂  @kezya_steffyn Akka thank you for coming back ..this time so much stronger than before 💖✌️💪...your dedication and your positivity is literally making this a memorable moment  Your vocals have did the magic 🪄 Out here !!! And iam really happy for our upcoming projects together 💖🤗  Day by day your creativity ideas have helped me to build myself and move a step forward in this journey so thanks a lot akka 💖💖💖  Me working on this project ...it's that I loved working on this totally coz it's my first time  And making the lyrical video ...iam so happy that you trusted me 😂 and I'm happy we both together made a really good 💖  Guys! support if you like , do share and comment...courtesy:crush eh advance valentine's day 😂😂😂💖 #vivekmervin #melaniemartinez  #valentineday #playdate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p1 = input(\"i)\tWhat do you like to do when you are free?\")\n",
        "p2 = input(\"ii)\tHow do you feel in the morning after waking up?\")\n",
        "p3 = input(\"iii)\tWhere do you see yourself in 5 years?\")\n",
        "p4 = input(\"iv) why did you choose this profession\")\n",
        "p5 = input(\"v) how close are you to your family\")\n",
        "p6 = input(\"vi) are you a honest person\")\n",
        "p7 = input(\"vii) what inspires you\")\n",
        "my_posts = p1+p2+p3+p4+p5+p6+p7\n",
        "mydata = pd.DataFrame(data={'type': [\"INTP\"], 'posts': [my_posts]})\n",
        "my_posts, dummy  = pre_process_text(mydata, remove_stop_words=True, remove_mbti_profiles=True)\n",
        "my_X_cnt = cntizer.transform(my_posts)\n",
        "my_X_tfidf =  tfizer.transform(my_X_cnt).toarray()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNb97Kz41BAt",
        "outputId": "fe900a21-f848-4680-cb21-3b49585c972d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i)\tWhat do you like to do when you are free?i play football\n",
            "ii)\tHow do you feel in the morning after waking up?i feel very much activated after waking up\n",
            "iii)\tWhere do you see yourself in 5 years?i see myself as an developed businessman and acquiring many jobs\n",
            "why did you choose this professioni like to work with data and see how can we manipulative it\n",
            "how close are you to your familyvery much close and i cant do anything without them\n",
            "are you a honest personyes i am very honest i will tell directly whether i can do it or not \n",
            "what inspires youthe people who smile even though they are in pain\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setup parameters for xgboost\n",
        "param = {}\n",
        "param['n_estimators'] = 200\n",
        "param['max_depth'] = 2\n",
        "param['nthread'] = 8\n",
        "param['learning_rate'] = 0.2\n",
        "result = []\n",
        "for l in range(len(personality_type)):\n",
        "    print(\"%s classifier trained\" % (personality_type[l]))\n",
        "    \n",
        "    Y = list_personality[:,l]\n",
        "\n",
        "    # split data into train and test sets\n",
        "    seed = 7\n",
        "    test_size = 0.33\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "\n",
        "    # fit model on training data\n",
        "    model = XGBClassifier(**param)\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # make predictions for my  data\n",
        "    y_pred = model.predict(my_X_tfidf)\n",
        "    result.append(y_pred[0])"
      ],
      "metadata": {
        "id": "5b3QBrUZYM5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fa8257e-3eb0-4f82-f6d5-ebf707a75e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IE: Introversion (I) | Extroversion (E) classifier trained\n",
            "NS: Intuition    (N) | Sensing      (S) classifier trained\n",
            "FT: Feeling      (F) | Thinking     (T) classifier trained\n",
            "JP: Judging      (J) | Perceiving   (P) classifier trained\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The personality of the data which we have taken: \", translate_back(result)) "
      ],
      "metadata": {
        "id": "celYFNnPYocE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50dccd1c-7594-4675-89d8-abeaf2b01f68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The personality of the data which we have taken:  ENFP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** THE END **"
      ],
      "metadata": {
        "id": "T1vhyoNnx34x"
      }
    }
  ]
}